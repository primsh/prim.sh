// Generated by scripts/gen-cli.ts â€” do not edit manually.
// Regenerate: pnpm gen:cli
// BEGIN:PRIM:CLI

import { createPrimFetch } from "@primsh/x402-client";
import { getConfig } from "./config.ts";
import { getFlag, hasFlag, resolvePassphrase } from "./flags.ts";

export function resolveInferUrl(argv: string[]): string {
  const flag = getFlag("url", argv);
  if (flag) return flag;
  if (process.env.PRIM_INFER_URL) return process.env.PRIM_INFER_URL;
  return "https://infer.prim.sh";
}

async function handleError(res: Response): Promise<never> {
  let message = `HTTP ${res.status}`;
  let code = "unknown";
  try {
    const body = (await res.json()) as { error?: { code: string; message: string } };
    if (body.error) {
      message = body.error.message;
      code = body.error.code;
    }
  } catch {
    // ignore parse error
  }
  process.stderr.write(`Error: ${message} (${code})\n`);
  process.exit(1);
}

export async function runInferCommand(sub: string, argv: string[]): Promise<void> {
  const baseUrl = resolveInferUrl(argv);
  const quiet = hasFlag("quiet", argv);
  const walletFlag = getFlag("wallet", argv);
  const passphrase = await resolvePassphrase(argv);
  const maxPaymentFlag = getFlag("max-payment", argv);
  const config = await getConfig();
  const primFetch = createPrimFetch({
    keystore:
      walletFlag !== undefined || passphrase !== undefined
        ? { address: walletFlag, passphrase }
        : true,
    maxPayment: maxPaymentFlag ?? process.env.PRIM_MAX_PAYMENT ?? "1.00",
    network: config.network,
  });

  if (!sub || sub === "--help" || sub === "-h") {
    console.log("Usage: prim infer <chat|embed|ls> [args] [flags]");
    console.log("");
    console.log("  Usage: prim infer chat --model MODEL --messages MESSAGES [--temperature VALUE] [--max-tokens VALUE] [--top-p VALUE]");
    console.log("  Usage: prim infer embed --model MODEL --input INPUT");
    console.log("  Usage: prim infer ls");
    process.exit(1);
  }

  switch (sub) {
    case "chat": {
      const model = getFlag("model", argv);
      const messages = getFlag("messages", argv);
      const temperature = getFlag("temperature", argv);
      const maxTokens = getFlag("max-tokens", argv);
      const topP = getFlag("top-p", argv);
      const frequencyPenalty = getFlag("frequency-penalty", argv);
      const presencePenalty = getFlag("presence-penalty", argv);
      const stop = getFlag("stop", argv);
      const stream = hasFlag("stream", argv);
      const tools = getFlag("tools", argv);
      const toolChoice = getFlag("tool-choice", argv);
      const responseFormat = getFlag("response-format", argv);
      if (!model || !messages) {
        process.stderr.write(
          "Usage: prim infer chat --model MODEL --messages MESSAGES [--temperature VALUE] [--max-tokens VALUE] [--top-p VALUE]\n",
        );
        process.exit(1);
      }
      const reqBody: Record<string, unknown> = {};
      reqBody.model = model;
      reqBody.messages = messages;
      if (temperature) reqBody.temperature = Number(temperature);
      if (maxTokens) reqBody.max_tokens = Number(maxTokens);
      if (topP) reqBody.top_p = Number(topP);
      if (frequencyPenalty) reqBody.frequency_penalty = Number(frequencyPenalty);
      if (presencePenalty) reqBody.presence_penalty = Number(presencePenalty);
      if (stop) reqBody.stop = stop;
      if (stream) reqBody.stream = true;
      if (tools) reqBody.tools = tools;
      if (toolChoice) reqBody.tool_choice = toolChoice;
      if (responseFormat) reqBody.response_format = responseFormat;
      const res = await primFetch(`${baseUrl}/v1/chat`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(reqBody),
      });
      if (!res.ok) return handleError(res);
      const data = await res.json();
      if (quiet) {
        console.log(JSON.stringify(data));
      } else {
        console.log(JSON.stringify(data, null, 2));
      }
      break;
    }

    case "embed": {
      const model = getFlag("model", argv);
      const input = getFlag("input", argv);
      if (!model || !input) {
        process.stderr.write(
          "Usage: prim infer embed --model MODEL --input INPUT\n",
        );
        process.exit(1);
      }
      const reqBody: Record<string, unknown> = {};
      reqBody.model = model;
      reqBody.input = input;
      const res = await primFetch(`${baseUrl}/v1/embed`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(reqBody),
      });
      if (!res.ok) return handleError(res);
      const data = await res.json();
      if (quiet) {
        console.log(JSON.stringify(data));
      } else {
        console.log(JSON.stringify(data, null, 2));
      }
      break;
    }

    case "ls": {
      const res = await primFetch(`${baseUrl}/v1/models`);
      if (!res.ok) return handleError(res);
      const data = await res.json();
      if (quiet) {
        console.log(JSON.stringify(data));
      } else {
        console.log(JSON.stringify(data, null, 2));
      }
      break;
    }

    default:
      console.log("Usage: prim infer <chat|embed|ls>");
      process.exit(1);
  }
}

// END:PRIM:CLI
